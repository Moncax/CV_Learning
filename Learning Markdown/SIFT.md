# SIFT/尺度不变特征转换
## Conception
SIFT(Scale-invariant feature transform)是一种检测图像的局部特征的算法，能够在空间中计算出极值点，并提取出其位置、尺度、旋转不变量。
## Method
- 首先从一组参考图像中提取对象的SIFT关键点，并将其存储在数据库中。
- 通过将新图像中的每个特征分别与此数据库进行比较，并根据其特征向量的欧几里得距离查找候选匹配特征，从而在新图像中识别出一个对象。
- 从整套匹配中，识别出与对象及其在新图像中的位置，比例和方向一致的关键点子集，以滤除<font color = red>good matches</font>。
- 通过使用广义霍夫变换的有效哈希表实现，可以快速实现consistent clusters的确定。
- 然后，将对3个或更多特征一致的一个对象及其姿势的每个cluster进行进一步的详细模型验证，并随后舍弃异常值。
- 最后，根据拟合的准确性和可能的​​错误匹配的数量，计算出一组特定的特征指示存在对象的概率。
- 通过所有这些测试的对象匹配可以高可信度地标识为正确。
## Overview
| 问题 | 解决技术 |
|---------|---------|
|关键的定位/规模/旋转问题   | DOG/规模空间金字塔/方向分配|
|几何扭曲变形|局部图像的方向平面的模糊/重采样|
|<font color = red>索引</font>和匹配|最近相邻(nearset neighbor)<br />最佳优先搜索(Best Bin First search)|
|集群识别|霍夫投票|
|模型验证/偏离值检测|线性最小二乘法|
|假设检验|贝叶斯公式|
### Main Stage
#### 尺度不变特征检测
- David Lowe的方法将图像特征转化为大型特征向量集，其中每个特征向量都与图像平移，缩放和旋转无关，部分特征向量与照明变化部分无关，并且对于局部几何扭曲有着很好的鲁棒性。（类比于视觉皮层神经元，这些神经元编码基本形式，颜色和运动以用于灵长类动物视觉中的物体检测）。
- 关键位置定义为在比例空间中应用的DOG结果的最大值和最小值一系列平滑和重新采样的图像。沿边缘的低对比度候选点和边缘响应点将被舍弃。主导方向（Dominant orientations）分配给局部关键点。
- 这些步骤确保了关键点对于匹配和识别而言更加稳定。然后，通过考虑关键位置半径附近的像素，局部图像方向平面的模糊化和重采样，可以获得对局部仿射失真具有鲁棒性的SIFT描述符。
#### 特征匹配和索引
- 索引包括存储SIFT密钥（key）和从新图像中识别匹配的密钥。Lowe用了从k-d树改进的最佳优先搜索（[best-fin-first search][1]），仅使用有限的计算量就可以识别高可能性的最近邻居（nearest neighbor）。BFF算法使用了对k-d树改进的搜索次序，以便按查询位置的最近距离来搜索特征空间中的<font color = red>[bin][1]（不懂）</font>。为有效判断搜索次序，其需要使用堆结构的优先队列。
- 通过从训练图像得到的关键点数据库里识别最近邻居，可以找到每个关键点的最佳候选匹配。最近邻居定义为从每个给定的SIFT描述符向量里欧氏距离最小的关键点。匹配正确的可能性通过取最近邻的距离与次近邻的距离之比确定。
- Lowe的[paper][2]里拒绝了所有距离比大于0.8的匹配，这可以消除90%的错误匹配而只舍弃了低于5%的正确匹配。进一步提高BFF搜索的效率可以在检查了头200个最近邻候选点后停止。对于具有100,000个关键点的数据库，这可以使精确的最近邻居搜索的速度提高大约2个数量级，但正确匹配的数量损失不到5%。

[1]:https://en.wikipedia.org/wiki/Best_bin_first
[2]:http://ceessnoek.info/courses/computervisionbylearning/2014/lowe-ijcv2004.pdf

 
