# SIFT/尺度不变特征转换
## Conception
SIFT(Scale-invariant feature transform)是一种检测图像的局部特征的算法，能够在空间中计算出极值点，并提取出其位置、尺度、旋转不变量。
## Method
- 首先从一组参考图像中提取对象的SIFT关键点，并将其存储在数据库中。
- 通过将新图像中的每个特征分别与此数据库进行比较，并根据其特征向量的欧几里得距离查找候选匹配特征，从而在新图像中识别出一个对象。
- 从整套匹配中，识别出与对象及其在新图像中的位置，比例和方向一致的关键点子集，以滤除<font color = red>good matches</font>。
- 通过使用广义霍夫变换的有效哈希表实现，可以快速实现consistent clusters的确定。
- 然后，将对3个或更多特征一致的一个对象及其姿势的每个cluster进行进一步的详细模型验证，并随后舍弃异常值。
- 最后，根据拟合的准确性和可能的​​错误匹配的数量，计算出一组特定的特征指示存在对象的概率。
- 通过所有这些测试的对象匹配可以高可信度地标识为正确。
## Overview
| 问题 | 解决技术 |
|---------|---------|
|关键的定位/规模/旋转问题   | DOG/规模空间金字塔/方向分配|
|几何扭曲变形|局部图像的方向平面的模糊/重采样|
|<font color = red>索引</font>和匹配|最近相邻(nearset neighbor)<br />最佳优先搜索(Best Bin First search)|
|集群识别|霍夫投票|
|模型验证/偏离值检测|线性最小二乘法|
|假设检验|贝叶斯公式|
### Main Stage
#### 尺度不变特征检测
- David Lowe的方法将图像特征转化为大型特征向量集，其中每个特征向量都与图像平移，缩放和旋转无关，部分特征向量与照明变化部分无关，并且对于局部几何扭曲有着很好的鲁棒性。（类比于视觉皮层神经元，这些神经元编码基本形式，颜色和运动以用于灵长类动物视觉中的物体检测）。
- 关键位置定义为在比例空间中应用的DOG结果的最大值和最小值一系列平滑和重新采样的图像。沿边缘的低对比度候选点和边缘响应点将被舍弃。主导方向（Dominant orientations）分配给局部关键点。
- 这些步骤确保了关键点对于匹配和识别而言更加稳定。然后，通过考虑关键位置半径附近的像素，局部图像方向平面的模糊化和重采样，可以获得对局部仿射失真具有鲁棒性的SIFT描述符。
#### 特征匹配和索引
- 索引包括存储SIFT密钥（key）和从新图像中识别匹配的密钥。Lowe用了从k-d树改进的最佳优先搜索（[best-fin-first search][1]），仅使用有限的计算量就可以识别高可能性的最近邻居（nearest neighbor）。BFF算法使用了对k-d树改进的搜索次序，以便按查询位置的最近距离来搜索特征空间中的<font color = red>[bin][1]（不懂）</font>。为有效判断搜索次序，其需要使用堆结构的优先队列。

- 通过从训练图像得到的关键点数据库里识别最近邻居，可以找到每个关键点的最佳候选匹配。最近邻居定义为从每个给定的SIFT描述符向量里欧氏距离最小的关键点。匹配正确的可能性通过取最近邻的距离与次近邻的距离之比确定。

- Lowe的[paper][2]里拒绝了所有距离比大于0.8的匹配，这可以消除90%的错误匹配而只舍弃了低于5%的正确匹配。进一步提高BFF搜索的效率可以在检查了头200个最近邻候选点后停止。对于具有100,000个关键点的数据库，这可以使精确的最近邻居搜索的速度提高大约2个数量级，但正确匹配的数量损失不到5%。

#### 通过霍夫投票的集群确认

- 霍夫变换用于聚类可靠的模型假设，来搜索对特定模型姿态一致的键。霍夫变换通过使用每个特征为所有与特征一致的物体姿态的投票（vote）来识别具有一致解释的特征集群。当发现一组特征投票支持一个物体的同一姿态时，正确解释的概率比任何单一特征都要高得多。在哈希表中创建一个条目，根据匹配假设预测模型的位置、方向和规模。搜索哈希表，以确定一个<font color = red>[bin][1]（不懂）</font>中至少有3个条目的所有集群，并按大小递减顺序对这些bin进行排序。
- 每个SIFT关键点可以指定2D空间的位置，规模和方向，并且每一个数据库里匹配的点会记录自己对训练图像里找到点的相对参数。 这四个参数蕴含的相似性变换只能是6个自由度姿势空间的3D物体的一种近似，并且对所有非刚性的变形没有效果。因此，Lowe的[paper][2]使用了更宽的bin大小，方向变换宽度为30度，比例因子为2， 以及最大投影训练图像尺寸（使用预测比例）的0.25倍 




[1]:https://en.wikipedia.org/wiki/Best_bin_first
[2]:http://ceessnoek.info/courses/computervisionbylearning/2014/lowe-ijcv2004.pdf

 
